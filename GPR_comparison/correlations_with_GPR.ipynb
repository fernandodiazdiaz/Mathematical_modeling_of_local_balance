{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.linalg as la\n",
    "from scipy.stats import linregress, spearmanr, kendalltau, pearsonr\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from draw_network import draw_network\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick',labelsize=22)\n",
    "matplotlib.rc('ytick',labelsize=16)\n",
    "matplotlib.rc('font',size = 24)\n",
    "matplotlib.rc('legend',fontsize = 17)\n",
    "matplotlib.rc('figure',titlesize = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_df():\n",
    "    \n",
    "    # import and clean the dataframe with alliances and conflicts\n",
    "    \n",
    "    df = pd.read_csv('../CoW_data/allies_and_enemies_1816_2014_iso.csv')\n",
    "\n",
    "    df = df[(df['alliance'] != 0) | (df['conflict']!=0)]   #filter entries with no link\n",
    "    \n",
    "    df['weight'] = df['alliance']+df['conflict']+df['alliance']*df['conflict']   # merge alliances and conflicts in a single column\n",
    "    df = df.drop(columns = ['alliance','conflict'])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def create_network(df, year, giant_component = True):\n",
    "    \n",
    "    # returns a Graph object corresponding to the international relations network of the given year\n",
    "    # edges have a weighted attribute which can be 1 or -1\n",
    "    \n",
    "    df2 = df[df['year']==year]   # select one particular year\n",
    "    G = nx.from_pandas_edgelist(df2, source ='statea', target = 'stateb', edge_attr='weight')\n",
    "    \n",
    "    # take only the giant component\n",
    "    if giant_component:\n",
    "        GC = max(nx.connected_components(G), key=len)\n",
    "        G = G.subgraph(GC)\n",
    "    return G\n",
    "\n",
    "\n",
    "def local_balance(G, country):   \n",
    "    \n",
    "    ### find node balance of a given country for one specific graph (i.e. one year)   ###\n",
    "    # find the balance index of the specific country\n",
    "    \n",
    "    idx = np.where(np.array(G.nodes()) == country)[0][0]    \n",
    "    \n",
    "    # calculate signed communicability\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    A0 = np.abs(A)\n",
    "    \n",
    "    Comm = la.expm(A)\n",
    "    Comm0 = la.expm(A0)\n",
    "    \n",
    "    # calculate balance\n",
    "    Ki = np.diag(Comm)/np.diag(Comm0)       # node balance\n",
    "    \n",
    "    return Ki[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def local_balance_timeseries(country, year_range = [1816,2014]):\n",
    "    \n",
    "    # finds the local balance for several years and creates a balance time series for a specific country\n",
    "    # Input:\n",
    "    # country: string with the iso-3 code of the country for which to compute the local balance time series\n",
    "    # year_range (optional): list with the first and last year of the time series\n",
    "    # Output:\n",
    "    # years_v: 1D array with the years of the time series\n",
    "    # Kloc: 1D array with the local balance values for each year\n",
    "    \n",
    "    df = initialize_df()\n",
    "    years_v = np.arange(year_range[0],year_range[1]+1)\n",
    "    Kloc = np.zeros(len(years_v))\n",
    "    \n",
    "    for i, year in enumerate(years_v):\n",
    "\n",
    "        G = create_network(df, year)\n",
    "        if country not in G.nodes():\n",
    "            Kloc[i] = None\n",
    "        else:\n",
    "            Kloc[i] = local_balance(G, country)\n",
    "\n",
    "    return years_v, Kloc\n",
    "\n",
    "\n",
    "def randomize_timeseries(time_series):\n",
    "\n",
    "    # Randomize a time series by shuffling its values\n",
    "    # Input:\n",
    "    # time_series: 1D array of values\n",
    "    # Output:\n",
    "    # time_series_copy: 1D array of values, shuffled\n",
    "\n",
    "    # Shuffle only the non-NaN values\n",
    "    time_series_copy = time_series.copy()   # note for myself: I need to make a copy because otherwise the original time series gets randomized outside this function too\n",
    "    mask_non_nan = ~np.isnan(time_series_copy)\n",
    "    shuffled_non_nan = time_series_copy[mask_non_nan]\n",
    "    np.random.shuffle(shuffled_non_nan)\n",
    "\n",
    "    # Place the shuffled non-NaN values back into the original time series using the mask\n",
    "    time_series_copy[mask_non_nan] = shuffled_non_nan\n",
    "\n",
    "    return time_series_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with GPR index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_correlation(timeseries_1, timeseries_2, type = 'spearman'):\n",
    "    \n",
    "    # computes the correlation between two time series\n",
    "    # Input:\n",
    "    # timeseries_1: 1D array of values\n",
    "    # timeseries_2: 1D array of values\n",
    "    # type: string, type of correlation to compute. Can be 'spearman', 'kendall' or 'pearson'\n",
    "    # Output:\n",
    "    # corr: correlation coefficient value\n",
    "    # p_value: p-value of the correlation\n",
    "\n",
    "    # filter nan values\n",
    "    timeseries_1 = timeseries_1.dropna()\n",
    "    timeseries_2 = timeseries_2.dropna()\n",
    "\n",
    "    # keep only the years common to both time series\n",
    "    overlap_index = timeseries_1.index.intersection(timeseries_2.index)\n",
    "    timeseries_1_ovlap = timeseries_1.loc[overlap_index]\n",
    "    timeseries_2_ovlap = timeseries_2.loc[overlap_index]\n",
    "\n",
    "    # compute correlations\n",
    "    if type == 'spearman':\n",
    "        corr, p_value = spearmanr(timeseries_1_ovlap.values, timeseries_2_ovlap.values)\n",
    "\n",
    "    elif type == 'kendall':\n",
    "        corr, p_value = kendalltau(timeseries_1_ovlap.values, timeseries_2_ovlap.values)\n",
    "\n",
    "    elif type == 'pearson':\n",
    "        corr, p_value = pearsonr(timeseries_1_ovlap.values, timeseries_2_ovlap.values)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Only spearman, kendall or pearson correlation allowed')\n",
    "\n",
    "    return corr, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning the GPR dataset ###\n",
    "\n",
    "# import GPR df\n",
    "GPR_df = pd.read_excel('GPR_data/GPR_individual_countries.xls')\n",
    "\n",
    "# select only the country GPR columns\n",
    "columns_to_use = list(filter(lambda col: col.startswith('GPRHC_'), GPR_df.columns))\n",
    "columns_to_use.insert(0, 'month')\n",
    "GPR_df = GPR_df[columns_to_use]\n",
    "\n",
    "# average the GPR every year\n",
    "GPR_df['Year'] = GPR_df['month'].dt.year \n",
    "GPR_year = GPR_df.groupby(by = 'Year').mean()  \n",
    "\n",
    "\n",
    "\n",
    "### filter countries for which there is sufficient data  ####\n",
    "\n",
    "countries = [item.replace('GPRHC_', '') for item in GPR_year.columns]\n",
    "\n",
    "filtered_countries = []\n",
    "for i, country in enumerate(countries):\n",
    "\n",
    "    # get balance index time series\n",
    "    years_v, Kloc = local_balance_timeseries(country)\n",
    "\n",
    "    # filter countries for which there is sufficient data\n",
    "    years_filtered = years_v[~np.isnan(Kloc)]\n",
    "    overlapping_years = set(years_filtered).intersection(set(np.arange(1900,2014)))\n",
    "    if len(overlapping_years) < 100:  # at least 100 data points per country\n",
    "        continue \n",
    "    else:\n",
    "        filtered_countries.append(country)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHN :\n",
      "Correlation true:  -0.16120886924958572\n",
      "P-value true:  0.08522115149453217\n",
      "Correlation random:  0.006982590529118299\n",
      "P-value random:  0.5054482518790696\n",
      "---\n",
      "FRA :\n",
      "Correlation true:  -0.4138069297908103\n",
      "P-value true:  4.730014550349174e-06\n",
      "Correlation random:  0.004048813866121486\n",
      "P-value random:  0.4990116521381114\n",
      "---\n",
      "GBR :\n",
      "Correlation true:  -0.18540203582419318\n",
      "P-value true:  0.04728602936260216\n",
      "Correlation random:  -0.0022038994461457307\n",
      "P-value random:  0.516602438925751\n",
      "---\n",
      "ITA :\n",
      "Correlation true:  -0.23730766195849443\n",
      "P-value true:  0.0106607036992213\n",
      "Correlation random:  0.00400034173259127\n",
      "P-value random:  0.4982353398872249\n",
      "---\n",
      "JPN :\n",
      "Correlation true:  -0.10930404967102217\n",
      "P-value true:  0.2578846123064046\n",
      "Correlation random:  0.009357446261629475\n",
      "P-value random:  0.5043816831648504\n",
      "---\n",
      "PRT :\n",
      "Correlation true:  -0.3668902390909809\n",
      "P-value true:  5.5056821147762176e-05\n",
      "Correlation random:  0.008116640962975423\n",
      "P-value random:  0.4836953155326624\n",
      "---\n",
      "RUS :\n",
      "Correlation true:  -0.3136984139509193\n",
      "P-value true:  0.0006404283361234428\n",
      "Correlation random:  -0.0012413465580829064\n",
      "P-value random:  0.5110397257740708\n",
      "---\n",
      "TUR :\n",
      "Correlation true:  -0.006730845103763908\n",
      "P-value true:  0.9430853347569946\n",
      "Correlation random:  0.0105285791536774\n",
      "P-value random:  0.512949527061922\n",
      "---\n",
      "USA :\n",
      "Correlation true:  -0.5479917935768959\n",
      "P-value true:  2.3171922658858753e-10\n",
      "Correlation random:  0.0006709917409127497\n",
      "P-value random:  0.5180319208352452\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "M = 500   # number of randomizations\n",
    "corr_type = 'spearman'\n",
    "prefix = 'GPRHC_'\n",
    "\n",
    "# initialize stuff\n",
    "corr_true = np.zeros(len(filtered_countries));     # correlation for the true time series\n",
    "p_values_true = np.zeros(len(filtered_countries));  # p-value for the true time series\n",
    "\n",
    "corr_rand_avg = np.zeros(len(filtered_countries))      # avg correlation for randomized time series\n",
    "p_values_rand_avg = np.zeros(len(filtered_countries))   # avg p-value for randomized time series\n",
    "\n",
    "for i, country in enumerate(filtered_countries):\n",
    "\n",
    "    GPR_ts = GPR_year[prefix+country]      # get GPR index time series\n",
    "\n",
    "    # get balance index time series and compute correlations\n",
    "    years_v, Kloc = local_balance_timeseries(country)\n",
    "    Kloc_ts = pd.Series(Kloc, index = years_v)\n",
    "    corr_true[i], p_values_true[i] = compute_correlation(GPR_ts, Kloc_ts, type = corr_type)\n",
    "\n",
    "    # correlations for the randomized time series\n",
    "    for _ in range(M):\n",
    "        # randomize time series\n",
    "        Kloc_aux = np.copy(Kloc)\n",
    "        Kloc_rand = randomize_timeseries(Kloc_aux)\n",
    "\n",
    "        # compute correlations\n",
    "        Kloc_ts_rand = pd.Series(Kloc_rand, index = years_v)\n",
    "        corr_rand, p_value_rand = compute_correlation(GPR_ts, Kloc_ts_rand, type = corr_type)\n",
    "        corr_rand_avg[i] += corr_rand\n",
    "        p_values_rand_avg[i] += p_value_rand\n",
    "\n",
    "    corr_rand_avg /= M\n",
    "    p_values_rand_avg /= M\n",
    "\n",
    "    print(country,':')\n",
    "    print('Correlation true: ', corr_true[i])\n",
    "    print('P-value true: ', p_values_true[i])\n",
    "    print('Correlation random: ', corr_rand_avg[i])\n",
    "    print('P-value random: ', p_values_rand_avg[i])\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapas_scikit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
